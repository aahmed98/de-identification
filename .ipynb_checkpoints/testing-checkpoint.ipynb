{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pre-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessing code\n",
    "from src.preprocess import PreProcessor, df_to_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save paths to the available datasets\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "class Dataset(NamedTuple):\n",
    "    \"\"\"\n",
    "    Interface for accessing data folders.\n",
    "    \"\"\"\n",
    "    title: str\n",
    "    preprocessed_folder: str\n",
    "    raw_folders: List[str]\n",
    "\n",
    "SAMPLE_DATA = Dataset(\n",
    "    title = \"sample_data\",\n",
    "    preprocessed_folder = \"../data/preprocessed/sample_data/\",\n",
    "    raw_folders = [\"docs/Track1-de-indentification/PHI/\"]\n",
    ")\n",
    "\n",
    "GOLD_1 = Dataset(\n",
    "    title = \"gold_1\",\n",
    "    preprocessed_folder = \"../data/preprocessed/gold_1/\",\n",
    "    raw_folders = [\"../data/raw/training-PHI-Gold-Set1/\"]\n",
    ")\n",
    "\n",
    "GOLD_FULL = Dataset(\n",
    "    title = \"gold_full\",\n",
    "    preprocessed_folder = \"../data/preprocessed/gold_full/\",\n",
    "    raw_folders = [\"../data/raw/training-PHI-Gold-Set1/\",\"../data/raw/training-PHI-Gold-Set2/\"]\n",
    ")\n",
    "\n",
    "GOLD_TEST = Dataset(\n",
    "    title = \"gold_test\",\n",
    "    preprocessed_folder = \"../data/preprocessed/gold_full/\",\n",
    "    raw_folders = [\"../data/raw/testing-PHI-Gold-fixed/\"]\n",
    ")\n",
    "\n",
    "DATASETS = [SAMPLE_DATA,GOLD_1,GOLD_FULL, GOLD_TEST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick dataset and define loading boolean\n",
    "train_data = DATASETS[0]\n",
    "test_data = DATASETS[3]\n",
    "isLoading = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "# of Tag Processing Errors:  1\n",
      "Files with errors:  ['320-01.xml']\n",
      "Shape of X:  (234, 471)\n",
      "Shape of y:  (234, 471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "max length:  471\n"
     ]
    }
   ],
   "source": [
    "# attach data to PreProcessor object.\n",
    "pp = PreProcessor(train_data.title)\n",
    "if isLoading:\n",
    "    X_train,y_train,df_train = pp.get_data(train_data.preprocessed_folder,isLoading = isLoading)\n",
    "else:\n",
    "    X_train,y_train,df_train = pp.get_data(train_data.raw_folders,isLoading = isLoading)\n",
    "print(\"max length: \",pp.max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_ids</th>\n",
       "      <th>characters</th>\n",
       "      <th>padded_sentence</th>\n",
       "      <th>padded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320-01</td>\n",
       "      <td>[Record, date, :, 2080, -, 03, -, 13, Ms, ., L...</td>\n",
       "      <td>[542, 1676, 567, 1751, 580, 564, 580, 483, 142...</td>\n",
       "      <td>[O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, I-DA...</td>\n",
       "      <td>[1, 1, 1, 25, 15, 15, 15, 15, 1, 1, 6, 12, 1, ...</td>\n",
       "      <td>[(3, 9), (10, 14), (14, 15), (16, 20), (20, 21...</td>\n",
       "      <td>[542, 1676, 567, 1751, 580, 564, 580, 483, 142...</td>\n",
       "      <td>[1, 1, 1, 25, 15, 15, 15, 15, 1, 1, 6, 12, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320-01</td>\n",
       "      <td>[Met, with, PCP, in, Feb, for, multiple, issue...</td>\n",
       "      <td>[833, 1230, 995, 530, 805, 172, 801, 1594, 151...</td>\n",
       "      <td>[O, O, O, O, B-DATE, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[1, 1, 1, 1, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[(143, 146), (147, 151), (152, 155), (156, 158...</td>\n",
       "      <td>[833, 1230, 995, 530, 805, 172, 801, 1594, 151...</td>\n",
       "      <td>[1, 1, 1, 1, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320-01</td>\n",
       "      <td>[No, h, /, o, macro, or, microvascular, compli...</td>\n",
       "      <td>[1502, 976, 1452, 253, 288, 1636, 1290, 548, 823]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[(1504, 1506), (1507, 1508), (1508, 1509), (15...</td>\n",
       "      <td>[1502, 976, 1452, 253, 288, 1636, 1290, 548, 8...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>320-01</td>\n",
       "      <td>[Hypertensive, disorder, :, dx, 2060, s, ,, wa...</td>\n",
       "      <td>[477, 1785, 567, 1613, 1096, 685, 1510, 155, 1...</td>\n",
       "      <td>[O, O, O, O, B-DATE, I-DATE, O, O, O, O, O, O,...</td>\n",
       "      <td>[1, 1, 1, 1, 25, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
       "      <td>[(1549, 1561), (1562, 1570), (1571, 1572), (15...</td>\n",
       "      <td>[477, 1785, 567, 1613, 1096, 685, 1510, 155, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 25, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320-01</td>\n",
       "      <td>[H, ., pylori, serology, +, Helicobacter, pylo...</td>\n",
       "      <td>[181, 823, 208, 1135, 744, 653, 208, 567, 1135...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-DATE, O, O, O...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25, 1, 1, 1, 1,...</td>\n",
       "      <td>[(1771, 1772), (1772, 1773), (1774, 1780), (17...</td>\n",
       "      <td>[181, 823, 208, 1135, 744, 653, 208, 567, 1135...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                                           sentence  \\\n",
       "0  320-01  [Record, date, :, 2080, -, 03, -, 13, Ms, ., L...   \n",
       "1  320-01  [Met, with, PCP, in, Feb, for, multiple, issue...   \n",
       "2  320-01  [No, h, /, o, macro, or, microvascular, compli...   \n",
       "3  320-01  [Hypertensive, disorder, :, dx, 2060, s, ,, wa...   \n",
       "4  320-01  [H, ., pylori, serology, +, Helicobacter, pylo...   \n",
       "\n",
       "                                        sentence_ids  \\\n",
       "0  [542, 1676, 567, 1751, 580, 564, 580, 483, 142...   \n",
       "1  [833, 1230, 995, 530, 805, 172, 801, 1594, 151...   \n",
       "2  [1502, 976, 1452, 253, 288, 1636, 1290, 548, 823]   \n",
       "3  [477, 1785, 567, 1613, 1096, 685, 1510, 155, 1...   \n",
       "4  [181, 823, 208, 1135, 744, 653, 208, 567, 1135...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, B-DATE, I-DATE, I-DATE, I-DATE, I-DA...   \n",
       "1  [O, O, O, O, B-DATE, O, O, O, O, O, O, O, O, O...   \n",
       "2                        [O, O, O, O, O, O, O, O, O]   \n",
       "3  [O, O, O, O, B-DATE, I-DATE, O, O, O, O, O, O,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, B-DATE, O, O, O...   \n",
       "\n",
       "                                          labels_ids  \\\n",
       "0  [1, 1, 1, 25, 15, 15, 15, 15, 1, 1, 6, 12, 1, ...   \n",
       "1  [1, 1, 1, 1, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "2                        [1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "3  [1, 1, 1, 1, 25, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25, 1, 1, 1, 1,...   \n",
       "\n",
       "                                          characters  \\\n",
       "0  [(3, 9), (10, 14), (14, 15), (16, 20), (20, 21...   \n",
       "1  [(143, 146), (147, 151), (152, 155), (156, 158...   \n",
       "2  [(1504, 1506), (1507, 1508), (1508, 1509), (15...   \n",
       "3  [(1549, 1561), (1562, 1570), (1571, 1572), (15...   \n",
       "4  [(1771, 1772), (1772, 1773), (1774, 1780), (17...   \n",
       "\n",
       "                                     padded_sentence  \\\n",
       "0  [542, 1676, 567, 1751, 580, 564, 580, 483, 142...   \n",
       "1  [833, 1230, 995, 530, 805, 172, 801, 1594, 151...   \n",
       "2  [1502, 976, 1452, 253, 288, 1636, 1290, 548, 8...   \n",
       "3  [477, 1785, 567, 1613, 1096, 685, 1510, 155, 1...   \n",
       "4  [181, 823, 208, 1135, 744, 653, 208, 567, 1135...   \n",
       "\n",
       "                                       padded_labels  \n",
       "0  [1, 1, 1, 25, 15, 15, 15, 15, 1, 1, 6, 12, 1, ...  \n",
       "1  [1, 1, 1, 1, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 1, 1, 1, 25, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 25, 1, 1, 1, 1,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data exploration\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-50b1b5c69d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_test_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_folders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misLoading\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misLoading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\de-identification\\src\\preprocess.py\u001b[0m in \u001b[0;36mcreate_test_set\u001b[1;34m(self, test_folders, train_folders, isLoading)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misLoading\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_folders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misTrainSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_train_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misLoading\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\de-identification\\src\\preprocess.py\u001b[0m in \u001b[0;36mprocess_data\u001b[1;34m(self, data_sets, isTrainSet)\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m                 \u001b[0mnote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TEXT\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m                 \u001b[0mnote_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote_characters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misTrainSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m                 \u001b[0ms_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mt_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\de-identification\\src\\preprocess.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, note, isTrainSet)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords_seen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnote_tokens\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add tokens to vocab set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mnote_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace_unknowns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnote_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnote_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote_characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\de-identification\\src\\preprocess.py\u001b[0m in \u001b[0;36mreplace_unknowns\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[0mcurrent_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcurrent_token\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords_seen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                     \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UNK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# load test set\n",
    "X_test,y_test,df_test = pp.create_test_set(test_data.raw_folders,isLoading = isLoading, test_data.title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
